{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNfo10cl4BpQQmr9JVwtQku",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sak2004/Neural_Network_From_Scratch/blob/main/Neural_Network_UsingNumpy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "P1uZEWBh-0tY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creation two layers of 3 neurons and inputing 4 variables"
      ],
      "metadata": {
        "id": "3FBgxXwiM-vu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "inputs = [[1, 2, 3, 2.5],   # 4 inputs to neuron\n",
        "          [2., 5., -1., 2],\n",
        "          [-1.5, 2.7, 3.3, -0.8]]\n",
        "\n",
        "weights = [[0.2, 0.8, -0.5, 1],\n",
        "           [0.5, -0.91, 0.26, -0.5],    # weights for each input to 3 neuron\n",
        "           [-0.26, -0.27, 0.17, 0.87]]\n",
        "\n",
        "biases = [2, 3, 0.5] # biases for each neuron\n",
        "\n",
        "weights2 = [[0.1, -0.14, 0.5],\n",
        "            [-0.5, 0.12, -0.33],\n",
        "            [-0.44, 0.73, -0.13]]\n",
        "\n",
        "biases2 = [-1, 2, -0.5]\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "inputs_array = np.array(inputs)\n",
        "weights_array = np.array(weights)\n",
        "biases_array = np.array(biases)\n",
        "weights2_array = np.array(weights2)\n",
        "biases2_array = np.array(biases2)\n",
        "\n",
        "# Calculate the output of the first layer\n",
        "layer1_outputs = np.dot(inputs_array, weights_array.T) + biases_array\n",
        "\n",
        "# Calculate the output of the second layer\n",
        "layer2_outputs = np.dot(layer1_outputs, weights2_array.T) + biases2_array\n",
        "\n",
        "print(layer2_outputs) # here input value passed though two layers using simple matrix multiplication between input and transpose of weights and addition of biases"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xaq3j6fvLgNt",
        "outputId": "24436559-b7e5-453f-81b0-0e4faa857a90"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.5031  -1.04185 -2.03875]\n",
            " [ 0.2434  -2.7332  -5.7633 ]\n",
            " [-0.99314  1.41254 -0.35655]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nnfs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLgkIndjWR_0",
        "outputId": "fb253644-81d1-442f-87d9-c8ad23cb7599"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nnfs\n",
            "  Downloading nnfs-0.5.1-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from nnfs) (2.0.2)\n",
            "Downloading nnfs-0.5.1-py3-none-any.whl (9.1 kB)\n",
            "Installing collected packages: nnfs\n",
            "Successfully installed nnfs-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nnfs #using nnfs to generate a spiral data set\n",
        "from nnfs.datasets import spiral_data\n",
        "nnfs.init()\n",
        "X,y =spiral_data(samples=100,classes= 3)"
      ],
      "metadata": {
        "id": "WvFzOzLYXuhl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Creating Dense Function Class\n"
      ],
      "metadata": {
        "id": "o1SVvho1TUKH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Layer_Dense:\n",
        "  def __init__(self,n_inputs,n_neurons):\n",
        "    self.weights = 0.10 * np.random.randn(n_inputs,n_neurons)\n",
        "    self.biases = np.zeros((1,n_neurons))\n",
        "  def forward_pass(self,inputs):\n",
        "    self.output = np.dot(inputs,self.weights) + self.biases\n",
        "\n",
        "dense1 = Layer_Dense(2,3)\n",
        "dense1.forward_pass(X)\n",
        "print(dense1.output[:5])\n",
        "\n"
      ],
      "metadata": {
        "id": "Wg-Rn9ytM7mO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cefbc800-fd9a-45dc-9839-d3069cc24064"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.          0.          0.        ]\n",
            " [-0.00104752  0.00113954 -0.00047984]\n",
            " [-0.00274148  0.00317292 -0.00086922]\n",
            " [-0.00421884  0.00526663 -0.00055913]\n",
            " [-0.00577077  0.00714014 -0.0008943 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Implementing Activation Layers\n"
      ],
      "metadata": {
        "id": "u6tLXg3gVg5C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementing ReLu Class as Activation Layer"
      ],
      "metadata": {
        "id": "9RPiBSoNWEMB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Activation_Relu :\n",
        "  def forward_pass(self,inputs):\n",
        "    self.output = np.maximum(0,inputs)\n"
      ],
      "metadata": {
        "id": "dPUPwad4Vnx3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementing Softmax Activation Function for predicted Outputs"
      ],
      "metadata": {
        "id": "2Lf-wUo4WY5O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Activation_Softmax:\n",
        "  def forward(self,inputs):\n",
        "\n",
        "    exp_value = np.exp(inputs - np.max(inputs,axis=1,keepdims=True))\n",
        "    probabilities = exp_value / np.sum(exp_value,axis=1,keepdims=True)\n",
        "    self.output = probabilities"
      ],
      "metadata": {
        "id": "o_hAn5XTVvac"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SZW7x-SeXMAF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}